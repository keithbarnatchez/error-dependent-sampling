}
powers
# group means
res_means <- c(18,18,16)
att_means <- c(16,15,14)
ovr_means <- c(res_means, att_means)
# pooled sd
sd <- 10
n_grid <- seq(60,1020,by=240)
nsim <- 1e4
powers <- rep(NA,length(n_grid))
for (n in 1:length(n_grid)) {
was_sig <- rep(NA,nsim)
print(n)
for (s in 1:nsim) {
# generate data according to group means (with sample size evenly split)
mins_vec <- c(rnorm(n_grid[n]/6,mean=res_means[1],sd=sd),
rnorm(n_grid[n]/6,mean=res_means[2],sd=sd),
rnorm(n_grid[n]/6,mean=res_means[3],sd=sd),
rnorm(n_grid[n]/6,mean=att_means[1],sd=sd),
rnorm(n_grid[n]/6,mean=att_means[2],sd=sd),
rnorm(n_grid[n]/6,mean=att_means[3],sd=sd))
# make vector of group labels (numbered 1/5)
group_vec <- rep(1:6,each=n_grid[n]/6)
# make a dataframe to run an anova
df <- data.frame(mins=mins_vec,group=group_vec)
# run an ANOVA test of mins on group
anova_res <- aov(mins~group,data=df)
sum_test = unlist(summary(anova_res))
pval <- sum_test[["Pr(>F)1"]]
# assign curr iter of was_sig 1 if pval is less than 0.05
was_sig[s] <- ifelse(pval<0.05,1,0)
}
# average the was_sigs to get power for current sample size
powers[n] <- mean(was_sig)
}
powers
library(tidyverse)
# make a line plot of power vs n with the theme_bw
plot_df %>% ggplot(aes(x=n,y=power)) +
geom_line() +
theme_bw() +
labs(x="Sample Size",y="Power") +
scale_x_continuous(breaks=c(60,300,540,780,1020)) +
theme(axis.text.x=element_text(size=12),
axis.text.y=element_text(size=12),
axis.title.x=element_text(size=14),
axis.title.y=element_text(size=14),
legend.title=element_text(size=14),
legend.text=element_text(size=12),
legend.position="none")
plot_df <- data.frame(power=powers,n=n_grid)
# make a line plot of power vs n with the theme_bw
plot_df %>% ggplot(aes(x=n,y=power)) +
geom_line() +
theme_bw() +
labs(x="Sample Size",y="Power") +
scale_x_continuous(breaks=c(60,300,540,780,1020)) +
theme(axis.text.x=element_text(size=12),
axis.text.y=element_text(size=12),
axis.title.x=element_text(size=14),
axis.title.y=element_text(size=14),
legend.title=element_text(size=14),
legend.text=element_text(size=12),
legend.position="none")
# make a line plot of power vs n with the theme_bw
plot_df %>% ggplot(aes(x=n,y=power)) +
geom_line(color='steelblue') +
theme_bw() +
labs(x="Sample Size",y="Power") +
scale_x_continuous(breaks=c(60,300,540,780,1020)) +
theme(axis.text.x=element_text(size=12),
axis.text.y=element_text(size=12),
axis.title.x=element_text(size=14),
axis.title.y=element_text(size=14),
legend.title=element_text(size=14),
legend.text=element_text(size=12),
legend.position="none")
# make a line plot of power vs n with the theme_bw
plot_df %>% ggplot(aes(x=n,y=power)) +
geom_line(color='steelblue',size=1.5) +
theme_bw() +
labs(x="Sample Size",y="Power") +
scale_x_continuous(breaks=c(60,300,540,780,1020)) +
theme(axis.text.x=element_text(size=12),
axis.text.y=element_text(size=12),
axis.title.x=element_text(size=14),
axis.title.y=element_text(size=14),
legend.title=element_text(size=14),
legend.text=element_text(size=12),
legend.position="none")
# make a line plot of power vs n with the theme_bw
plot_df %>% ggplot(aes(x=n,y=power)) +
geom_line(color='steelblue',size=1.5) +
geom_point() +
theme_bw() +
labs(x="Sample Size",y="Power") +
scale_x_continuous(breaks=c(60,300,540,780,1020)) +
theme(axis.text.x=element_text(size=12),
axis.text.y=element_text(size=12),
axis.title.x=element_text(size=14),
axis.title.y=element_text(size=14),
legend.title=element_text(size=14),
legend.text=element_text(size=12),
legend.position="none")
# make a line plot of power vs n with the theme_bw
plot_df %>% ggplot(aes(x=n,y=power)) +
geom_line(color='steelblue',size=1.1) +
geom_point() +
theme_bw() +
labs(x="Sample Size",y="Power") +
scale_x_continuous(breaks=c(60,300,540,780,1020)) +
theme(axis.text.x=element_text(size=12),
axis.text.y=element_text(size=12),
axis.title.x=element_text(size=14),
axis.title.y=element_text(size=14),
legend.title=element_text(size=14),
legend.text=element_text(size=12),
legend.position="none")
# make a line plot of power vs n with the theme_bw
plot_df %>% ggplot(aes(x=n,y=power)) +
geom_line(color='steelblue',size=1.1) +
geom_point() +
theme_bw() +
labs(x="Sample Size",y="Power",
title='Power as a function of total sample size',
subtitle='Total sample size evenly divided among all groups') +
scale_x_continuous(breaks=c(60,300,540,780,1020)) +
theme(axis.text.x=element_text(size=12),
axis.text.y=element_text(size=12),
axis.title.x=element_text(size=14),
axis.title.y=element_text(size=14),
legend.title=element_text(size=14),
legend.text=element_text(size=12),
legend.position="none")
# make a line plot of power vs n with the theme_bw
plot_df %>% ggplot(aes(x=n,y=power)) +
geom_line(color='steelblue',size=1.1) +
geom_point() +
theme_bw() +
labs(x="Sample Size",y="Power",
title='Power as a function of total sample size',
subtitle='Total sample size evenly divided among all groups') +
scale_x_continuous(breaks=c(60,300,540,780,1020)) +
theme(axis.text.x=element_text(size=12),
axis.text.y=element_text(size=12),
axis.title.x=element_text(size=14),
axis.title.y=element_text(size=14),
legend.title=element_text(size=14),
legend.text=element_text(size=12),
legend.position="none") +
geom_hline(yintercept = 0.8)
# make a line plot of power vs n with the theme_bw
plot_df %>% ggplot(aes(x=n,y=power)) +
geom_line(color='steelblue',size=1.1) +
geom_point() +
theme_bw() +
labs(x="Sample Size",y="Power",
title='Power as a function of total sample size',
subtitle='Total sample size evenly divided among all groups') +
scale_x_continuous(breaks=c(60,300,540,780,1020)) +
theme(axis.text.x=element_text(size=12),
axis.text.y=element_text(size=12),
axis.title.x=element_text(size=14),
axis.title.y=element_text(size=14),
legend.title=element_text(size=14),
legend.text=element_text(size=12),
legend.position="none") +
geom_hline(yintercept = 0.8, color='red')
# make a line plot of power vs n with the theme_bw
plot_df %>% ggplot(aes(x=n,y=power)) +
geom_line(color='steelblue',size=1.1) +
geom_point() +
theme_bw() +
labs(x="Sample Size",y="Power",
title='Power as a function of total sample size',
subtitle='Total sample size evenly divided among all groups') +
scale_x_continuous(breaks=c(60,300,540,780,1020)) +
theme(axis.text.x=element_text(size=12),
axis.text.y=element_text(size=12),
axis.title.x=element_text(size=14),
axis.title.y=element_text(size=14),
legend.title=element_text(size=14),
legend.text=element_text(size=12),
legend.position="none") +
geom_hline(yintercept = 0.9, color='red')
(37000-4400)*0.05
640*4
37000-(4400)
(37000-(4400))*0.05
1630/4
3700/4000
3700/400
4000/37000
1630/37000
# sim-main.R
#
# Main file for conducting simulations for the me-dependent-sampling project
#-------------------------------------------------------------------------------
rm(list=ls())
setwd("~/Documents/research/me-dep-sampling/R")
source('data-functions.R')
source('estimation-functions.R')
if (Sys.info()['sysname'] == 'Linux') { # if on cluster, specify library path
.libPaths("~/R_packages")
}
packages <- c("tidyverse","mvtnorm",'SuperLearner','ggridges',
'doParallel','foreach')
package_list <- rownames(installed.packages())
for (pkg in packages) {  # This should output the actual package names
if (!(pkg %in% package_list)) {
stop("Package '", pkg, "' not installed")
}
}
#-------------------------------------------------------------------------------
# Need a few of the packages loaded
library(tidyverse)
library(SuperLearner)
library(ggridges)
# ------------------------------------------------------------------------------
# Set up relevant paths for output
flnm <- gsub(':','-',Sys.time()) # filename suffixed with date/time
flnm <- paste('sim_results_',gsub(' ','_',flnm),'.csv',sep = '')
simdir <- 'output/' # directory
fullpath <- paste(simdir,flnm,sep='') # construct path to final file name
library(doParallel)
library(foreach)
# ------------------------------------------------------------------------------
# Set up relevant paths for output
flnm <- gsub(':','-',Sys.time()) # filename suffixed with date/time
flnm <- paste('sim_results_',gsub(' ','_',flnm),'.csv',sep = '')
simdir <- 'output/' # directory
fullpath <- paste(simdir,flnm,sep='') # construct path to final file name
n <- 2500 ; p <- 3
delta <- c(-0.1,-0.6,-0.9)
nu <- c(0.1,-0.1,0.1)
beta <- c(1,2,-2) # outcome model main effects
tau <- 1 # constant treatment effect
gamma <- rep(1,3) # interaction effects with tmt c(0.5,2.1,-1.2)
eta <- c(0.6,-0.2,0.8,0.1,-0.3)
omega <- 0.1
rho <- 0.1 # relative size of the validation data
rho <- c(0.1, 0.2, 0.3, 0.4, 0.5) # relative size of the validation data
n <- c(500, 1000, 2500, 5000) # sample size
omega <- c(0.05,0.1,0.15,0.2) # severity of the measurement error
nsim <- 2 # number of iterations
nsim <- 2 # number of simulation iterations
# Vectorize every combination of rho, n, and omega and loop over these combos
param_combos <- expand.grid(rho=rho, n=n, omega=omega)
res_list <- list()
s=1
# Set up list of params for this iteration
params <- list(n=param_combos[s,'n'], omega=param_combos[s,'omega'],
rho=param_combos[s,'rho'],
p=p,
delta=delta,
nu=nu,
beta=beta,
gamma=gamma,
eta=eta,
tau=tau)
source('sim-functions.R')
# For current combination of parameters, run simulation
res <- main_sim(nsim,params)
source('sim-functions.R')
# For current combination of parameters, run simulation
res <- main_sim(nsim,params)
source('sim-functions.R')
# For current combination of parameters, run simulation
res <- main_sim(nsim,params)
View(res)
nsim
# Extract names from params
list2env(params, envir = environment())
# Carry out the simulation
sim_results <- foreach(i = 1:nsim, .combine = rbind) %dopar% {
sim_iter(n,p,delta,nu,beta,gamma,eta,omega,tau)
}
View(sim_results)
# add parameters to results dataframe
params_df <- as.data.frame(t(unlist(params)))
# Carry out the simulation
sim_results <- foreach(i = 1:nsim, .combine = cbind) %dopar% {
sim_iter(n,p,delta,nu,beta,gamma,eta,omega,tau)
}
# Simulate data
df <- gen_data(n,p,delta,nu,beta,gamma,eta,omega,tau)
# Estimate psi
psi_hat <- est_psi_a(df)
# Unpack output to store in df
psi_hat <- as.data.frame(unlist(psi_hat))
sim_iter(n,p,delta,nu,beta,gamma,eta,omega,tau)
# Carry out the simulation
sim_results <- foreach(i = 1:nsim, .combine = rbind) %dopar% {
sim_iter(n,p,delta,nu,beta,gamma,eta,omega,tau)
}
View(sim_results)
sim_results <- t(sim_results)
sim_iter(n,p,delta,nu,beta,gamma,eta,omega,tau)
# Simulate data
df <- gen_data(n,p,delta,nu,beta,gamma,eta,omega,tau)
# Estimate psi
psi_hat <- est_psi_a(df)
# Unpack output to store in df
psi_hat <- as.data.frame(unlist(psi_hat))
View(psi_hat)
# Unpack output to store in df
psi_hat <- as.data.frame(t(unlist(psi_hat)))
# Unpack output to store in df
psi_hat <- t(unlist(psi_hat))
# Estimate psi
psi_hat <- est_psi_a(df)
View(psi_hat)
# Estimate psi
psi_hat <- est_psi_a(df)
warnings()
# Unpack output to store in df
psi_hat <- data.frame(t(unlist(psi_hat)),stringsAsFactors = FALSE)
# Carry out the simulation
sim_results <- foreach(i = 1:nsim, .combine = rbind) %dopar% {
sim_iter(n,p,delta,nu,beta,gamma,eta,omega,tau)
}
View(sim_results)
View(sim_results)
sim_iter <- function(n,p,delta,nu,beta,gamma,eta,omega,tau) {
#' Function for simulating data
#'
#' Arguments:
#' - n: Sample size
#' - p: Number of covariates
#' - delta: Treatment effect
#' - nu: Outcome measurement error variance
#' - beta, tau, gamma: Outcome model coefficients
#'
#' Outputs:
#' - A dataframe containing the sim data
#'
#'
# Simulate data
df <- gen_data(n,p,delta,nu,beta,gamma,eta,omega,tau)
# Estimate psi
psi_hat <- est_psi_a(df)
# Unpack output to store in df
psi_hat <- data.frame(t(unlist(psi_hat)),stringsAsFactors = FALSE)
# Return data
return(psi_hat)
}
# Carry out the simulation
sim_results <- foreach(i = 1:nsim, .combine = rbind) %dopar% {
sim_iter(n,p,delta,nu,beta,gamma,eta,omega,tau)
}
# add parameters to results dataframe
params_df <- as.data.frame(t(unlist(params)))
# replicate params_df so that it has n total identical rows
params_df <- params_df[rep(seq_len(nrow(params_df)), each = nsim), ]
# combine params_df and sim_results
sim_results <- cbind(params_df, sim_results)
nsim <- 2 # number of simulation iterations
# Vectorize every combination of rho, n, and omega and loop over these combos
param_combos <- expand.grid(rho=rho, n=n, omega=omega)
rho <- c(0.2,0.3) # c(0.1, 0.2, 0.3, 0.4, 0.5) # relative size of the validation data
n <- c(500,1000) # c(500, 1000, 2500, 5000) # sample size
source('data-functions.R')
source('estimation-functions.R')
source('sim-functions.R')
n <- 2500 ; p <- 3
delta <- c(-0.1,-0.6,-0.9)
nu <- c(0.1,-0.1,0.1)
beta <- c(1,2,-2) # outcome model main effects
tau <- 1 # constant treatment effect
gamma <- rep(1,3) # interaction effects with tmt c(0.5,2.1,-1.2)
eta <- c(0.6,-0.2,0.8,0.1,-0.3)
omega <- 0.1
rho <- 0.1 # relative size of the validation data
rho <- c(0.2,0.3) # c(0.1, 0.2, 0.3, 0.4, 0.5) # relative size of the validation data
n <- c(500,1000) # c(500, 1000, 2500, 5000) # sample size
omega <- c(0.1) # c(0.05,0.1,0.15,0.2) # severity of the measurement error
nsim <- 2 # number of simulation iterations
# Vectorize every combination of rho, n, and omega and loop over these combos
param_combos <- expand.grid(rho=rho, n=n, omega=omega)
res_list <- list()
for (s in 1:length(param_combos)) {
# Set up list of params for this iteration
params <- list(n=param_combos[s,'n'], omega=param_combos[s,'omega'],
rho=param_combos[s,'rho'],
p=p,
delta=delta,
nu=nu,
beta=beta,
gamma=gamma,
eta=eta,
tau=tau)
# For current combination of parameters, run simulation
res <- main_sim(nsim,params)
# Store results
res_list[[s]] <- res
}
View(res_list)
final_res <- do.call(rbind, res_list)
View(final_res)
# Carry out the simulation
sim_results <- foreach(i = 1:nsim, .combine = rbind) %dopar% {
sim_iter(n,p,delta,nu,beta,gamma,eta,omega,tau)
}
View(sim_results)
# add parameters to results dataframe
params_df <- as.data.frame(t(unlist(params)))
# replicate params_df so that it has n total identical rows
params_df <- params_df[rep(seq_len(nrow(params_df)), each = nsim), ]
# combine params_df and sim_results
sim_results <- cbind(params_df, sim_results)
View(res_list)
View(res_list[[1]])
# sim-main.R
#
# Main file for conducting simulations for the me-dependent-sampling project
#-------------------------------------------------------------------------------
rm(list=ls())
source('data-functions.R')
source('estimation-functions.R')
source('sim-functions.R')
write.csv(res,filepath,row.names = FALSE)
# sim-main.R
#
# Main file for conducting simulations for the me-dependent-sampling project
#-------------------------------------------------------------------------------
rm(list=ls())
source('data-functions.R')
source('estimation-functions.R')
source('sim-functions.R')
#-------------------------------------------------------------------------------
# Check if on cluster to determine library path
if (Sys.info()['sysname'] == 'Linux') { # if on cluster, specify library path
.libPaths("~/R_packages")
}
#-------------------------------------------------------------------------------
# Ensure all required packages are installed
packages <- c("tidyverse","mvtnorm",'SuperLearner','ggridges',
'doParallel','foreach')
package_list <- rownames(installed.packages())
for (pkg in packages) {  # This should output the actual package names
if (!(pkg %in% package_list)) {
stop("Package '", pkg, "' not installed")
}
}
#-------------------------------------------------------------------------------
# Need a few of the packages loaded
library(tidyverse)
library(SuperLearner)
library(ggridges)
library(doParallel)
library(foreach)
# ------------------------------------------------------------------------------
# Set up relevant paths for output
flnm <- gsub(':','-',Sys.time()) # filename suffixed with date/time
flnm <- paste('sim_results_',gsub(' ','_',flnm),'.csv',sep = '')
simdir <- 'output/' # directory
fullpath <- paste(simdir,flnm,sep='') # construct path to final file name
# ------------------------------------------------------------------------------
# Setup parameters that remain constant across simulations
n <- 2500 ; p <- 3
delta <- c(-0.1,-0.6,-0.9)
nu <- c(0.1,-0.1,0.1)
beta <- c(1,2,-2) # outcome model main effects
tau <- 1 # constant treatment effect
gamma <- rep(1,3) # interaction effects with tmt c(0.5,2.1,-1.2)
eta <- c(0.6,-0.2,0.8,0.1,-0.3)
omega <- 0.1
rho <- 0.1 # relative size of the validation data
#-------------------------------------------------------------------------------
# Setup parameters that vary across simulations
rho <- c(0.2,0.3) # c(0.1, 0.2, 0.3, 0.4, 0.5) # relative size of the validation data
n <- c(500,1000) # c(500, 1000, 2500, 5000) # sample size
omega <- c(0.1) # c(0.05,0.1,0.15,0.2) # severity of the measurement error
#-------------------------------------------------------------------------------
# Main simulation
nsim <- 2 # number of simulation iterations
# Vectorize every combination of rho, n, and omega and loop over these combos
param_combos <- expand.grid(rho=rho, n=n, omega=omega)
res_list <- list()
for (s in 1:length(param_combos)) {
# Set up list of params for this iteration
params <- list(n=param_combos[s,'n'], omega=param_combos[s,'omega'],
rho=param_combos[s,'rho'],
p=p,
delta=delta,
nu=nu,
beta=beta,
gamma=gamma,
eta=eta,
tau=tau)
# For current combination of parameters, run simulation
res <- main_sim(nsim,params)
# Store results
res_list[[s]] <- res
}
final_res <- do.call(rbind, res_list)
#------------------------------------------------------------------------------
# Save output to csv
write.csv(res,filepath,row.names = FALSE)
View(final_res)
View(res)
param_combos
rho <- c(0.1, 0.2, 0.3, 0.4, 0.5) # relative size of the validation data
n <- c(500, 1000, 2500, 5000) # sample size
omega <- c(0.05,0.1,0.15,0.2) # severity of the measurement error
nsim <- 250 # number of simulation iterations
# Vectorize every combination of rho, n, and omega and loop over these combos
param_combos <- expand.grid(rho=rho, n=n, omega=omega)
param_combos
length(param_combos)
nrow(param_combos)
