# First, estimate the sampling probs
kappa_hat <- est_kappa(data,sl.lib)
data$kappa_hat <- kappa_hat
# Scale outcome to [0,1] interval
data$Ysc = shift_n_scale(data$Y)
data_reg <- data # %>% filter(R==1
# get estimate of E[Y|A=a,X] and P(A=a|X) via weighted regressions
outcome_mod <- SuperLearner::SuperLearner(Y=data_reg$Ysc,
X=data_reg %>% select(X, A),
SL.library= sl.lib,
obsWeights=as.double(data$R/data$kappa_hat),
verbose=FALSE)
m_hat1 <- predict(outcome_mod,
newdata=data %>% mutate(A=1))$pred
m_hat0 <- predict(outcome_mod,
newdata=data %>% mutate(A=0))$pred
m_hat1
summary(m_hat1)
# Similarly, get estimates of P(A=a|X) with weighted regressions
pi_mod <- SuperLearner::SuperLearner(Y=data$A,
X=data %>% select(X),
SL.library= sl.lib, #'SL.earth',
obsWeights=as.double(data$R/kappa_hat),
verbose=FALSE)
pi_hat1 <- predict(pi_mod,new_data=data)$pred ; pi_hat0 <- 1-pi_hat1
# Form the plug-in estimates
plugin <- m_hat1 - m_hat0
# Use these to form full-data-EIF pseudo-outcomes
psuedo_outcome <- with(data,
(m_hat1 - m_hat0) + (Ysc-m_hat1)*A/pi_hat1 - (Ysc-m_hat0)*(1-A)/(1-pi_hat0))
summary(pseudo_outcome)
summary(psuedo_outcome)
summary(logit_transform(psuedo_outcome))
# Regress the pseudo-outcomes on Z to get projection estimate of EIF
pseudo_mod <- SuperLearner::SuperLearner(Y=psuedo_outcome,
X=data %>% select(X,Astar,Ystar),
SL.library=sl.lib,
obsWeights=data$R,
verbose=FALSE)
eif_proj <- predict(pseudo_mod,newdata=data)$pred
# The TML is carried out in two updates. First, update kappa estimate
kappa_new <- glm(R ~  -1 + I(eif_proj/kappa_hat),
data=data,
offset=logit_transform(kappa_hat),
family=binomial())
kappa_new <- predict(kappa_new,type='response')
kappa_new <- trim(kappa_new,0.01)
# Construct clever covariates
H_A <- with(data, A/pi_hat1 - (1-A)/(1-pi_hat0))
H_1 <- with(data, 1/pi_hat1)
H_0 <- with(data, -1/(1-pi_hat0))
# Get eps estimate
m_mod_new <- glm(Ysc ~ -1 + H_A,
data=data,
family=binomial(),
weights=data$R/kappa_new,
offset=logit_transform(plugin))
eps <- coef(m_mod_new)
# With eps, we can update m1 and m0
m1_new <- plogis(qlogis(shift_n_scale(m_hat1)) + eps*H_1)
m0_new <- plogis(qlogis(shift_n_scale(m_hat0)) + eps*H_0)
mean(m1_new - m0_new)
# For current combination of parameters, run simulation
res <- main_sim(nsim,
params,parallel=FALSE)
new_plugin = m1_new - m0_new
# First, estimate the sampling probs
kappa_hat <- est_kappa(data,sl.lib)
data$kappa_hat <- kappa_hat
# Scale outcome to [0,1] interval
data$Ysc = shift_n_scale(data$Y)
data_reg <- data # %>% filter(R==1
# get estimate of E[Y|A=a,X] and P(A=a|X) via weighted regressions
outcome_mod <- SuperLearner::SuperLearner(Y=data_reg$Ysc,
X=data_reg %>% select(X, A),
SL.library= sl.lib,
obsWeights=as.double(data$R/data$kappa_hat),
verbose=FALSE)
m_hat1 <- predict(outcome_mod,
newdata=data %>% mutate(A=1))$pred
m_hat0 <- predict(outcome_mod,
newdata=data %>% mutate(A=0))$pred
# Similarly, get estimates of P(A=a|X) with weighted regressions
pi_mod <- SuperLearner::SuperLearner(Y=data$A,
X=data %>% select(X),
SL.library= sl.lib, #'SL.earth',
obsWeights=as.double(data$R/kappa_hat),
verbose=FALSE)
pi_hat1 <- predict(pi_mod,new_data=data)$pred ; pi_hat0 <- 1-pi_hat1
# Form the plug-in estimates
plugin <- m_hat1 - m_hat0
# Use these to form full-data-EIF pseudo-outcomes
psuedo_outcome <- with(data,
(m_hat1 - m_hat0) + (Ysc-m_hat1)*A/pi_hat1 - (Ysc-m_hat0)*(1-A)/(1-pi_hat0))
# Regress the pseudo-outcomes on Z to get projection estimate of EIF
pseudo_mod <- SuperLearner::SuperLearner(Y=psuedo_outcome,
X=data %>% select(X,Astar,Ystar),
SL.library=sl.lib,
obsWeights=data$R,
verbose=FALSE)
eif_proj <- predict(pseudo_mod,newdata=data)$pred
# The TML is carried out in two updates. First, update kappa estimate
kappa_new <- glm(R ~  -1 + I(eif_proj/kappa_hat),
data=data,
offset=logit_transform(kappa_hat),
family=binomial())
kappa_new <- predict(kappa_new,type='response')
kappa_new <- trim(kappa_new,0.01)
# Construct clever covariates
H_A <- with(data, A/pi_hat1 - (1-A)/(1-pi_hat0))
H_1 <- with(data, 1/pi_hat1)
H_0 <- with(data, -1/(1-pi_hat0))
# Get eps estimate
m_mod_new <- glm(Ysc ~ -1 + H_A,
data=data,
family=binomial(),
weights=data$R/kappa_new,
offset=logit_transform(plugin))
plugin
summary(logit_transform(plugin))
summary(plugin)
# get estimate of E[Y|A=a,X] and P(A=a|X) via weighted regressions
outcome_mod <- SuperLearner::SuperLearner(Y=data_reg$Ysc,
X=data_reg %>% select(X, A),
SL.library= sl.lib,
method='method.CC_nloglik',
obsWeights=as.double(data$R/data$kappa_hat),
verbose=FALSE)
m_hat1 <- predict(outcome_mod,
newdata=data %>% mutate(A=1))$pred
m_hat0 <- predict(outcome_mod,
newdata=data %>% mutate(A=0))$pred
# Similarly, get estimates of P(A=a|X) with weighted regressions
pi_mod <- SuperLearner::SuperLearner(Y=data$A,
X=data %>% select(X),
SL.library= sl.lib, #'SL.earth',
obsWeights=as.double(data$R/kappa_hat),
verbose=FALSE)
pi_hat1 <- predict(pi_mod,new_data=data)$pred ; pi_hat0 <- 1-pi_hat1
# Form the plug-in estimates
plugin <- m_hat1 - m_hat0
plugin
min(plugin)
max(plugin)
# Plots for the error-dependent sampling project
#-------------------------------------------------------------------------------
# Packages
library(tidyverse)
# Plots for the error-dependent sampling project
#-------------------------------------------------------------------------------
# Packages
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(reshape2)
library(ggridges)
library(ggtext)
path <- '../output/sim_results-2025-02-11-21-00-03.csv' # '../output/sim_results-2025-02-03-11-23-37.csv'  # '../output/sim_results-2025-01-20-08-07-44.csv'   #  '../output/sim_results-2024-09-05-07-34-53.csv'
res <- read.csv(path)
winsorize <- function(x,pctile=0.001) {
q <- quantile(x,probs=c(pctile,1-pctile))
x[x<q[1]] <- q[1]
x[x>q[2]] <- q[2]
return(x)
}
# Rename the plugin and onestep variables in res to pluginest and onestepest
res <- res %>% rename(pluginest = plugin, onestepest = onestep,
oracleest = oracle, naiveest = naive,
tmlest=tml,cvest=psi_hat_cv,tmlevmest=tml_evm,
tmlmidest=tml_mid, drcmdevmest=drcmd_evm,
tmlse=tmlse,
onestepse=onestepse,
tmlmidse=tml_midse,
tmlevmse=tml_evmse,
drcmdevmse = drcmd_evmse) %>%
mutate(onestepest=winsorize(onestepest),
pluginest=winsorize(pluginest))
library(tidyverse)
library(reshape2)
library(ggridges)
library(ggtext)
path <- '../output/sim_results-2025-02-11-21-00-03.csv' # '../output/sim_results-2025-02-03-11-23-37.csv'  # '../output/sim_results-2025-01-20-08-07-44.csv'   #  '../output/sim_results-2024-09-05-07-34-53.csv'
res <- read.csv(path)
winsorize <- function(x,pctile=0.001) {
q <- quantile(x,probs=c(pctile,1-pctile))
x[x<q[1]] <- q[1]
x[x>q[2]] <- q[2]
return(x)
}
# Rename the plugin and onestep variables in res to pluginest and onestepest
res <- res %>% rename(pluginest = plugin, onestepest = onestep,
oracleest = oracle, naiveest = naive,
tmlest=tml,cvest=psi_hat_cv,tmlevmest=tml_evm,
tmlmidest=tml_mid, drcmdevmest=drcmd_evm,
tmlse=tmlse,
onestepse=onestepse,
tmlmidse=tml_midse,
tmlevmse=tml_evmse,
drcmdevmse = drcmd_evmse) %>%
mutate(onestepest=winsorize(onestepest),
pluginest=winsorize(pluginest))
path <- '../output/sim_results-2025-02-11-21-00-03.csv' # '../output/sim_results-2025-02-03-11-23-37.csv'  # '../output/sim_results-2025-01-20-08-07-44.csv'   #  '../output/sim_results-2024-09-05-07-34-53.csv'
# Rename the plugin and onestep variables in res to pluginest and onestepest
res <- res %>% rename(pluginest = plugin, onestepest = onestep,
oracleest = oracle, naiveest = naive,
tmlest=tml,cvest=psi_hat_cv,tmlevmest=tml_evm,
tmlmidest=tml_mid, drcmdevmest=drcmd_evm,
tmlse=tmlse,
onestepse=onestepse,
tmlmidse=tml_midse,
tmlevmse=tml_evmse,
drcmdevmse = drcmd_evmse) %>%
mutate(onestepest=winsorize(onestepest),
pluginest=winsorize(pluginest))
path <- '../output/sim_results-2025-02-11-21-00-03.csv' # '../output/sim_results-2025-02-03-11-23-37.csv'  # '../output/sim_results-2025-01-20-08-07-44.csv'   #  '../output/sim_results-2024-09-05-07-34-53.csv'
res <- read.csv(path)
winsorize <- function(x,pctile=0.001) {
q <- quantile(x,probs=c(pctile,1-pctile))
x[x<q[1]] <- q[1]
x[x>q[2]] <- q[2]
return(x)
}
# Rename the plugin and onestep variables in res to pluginest and onestepest
res <- res %>% rename(pluginest = plugin, onestepest = onestep,
oracleest = oracle, naiveest = naive,
tmlest=tml,cvest=psi_hat_cv,tmlevmest=tml_evm,
tmlmidest=tml_mid, drcmdevmest=drcmd_evm,
tmlse=tmlse,
onestepse=onestepse,
tmlmidse=tml_midse,
tmlevmse=tml_evmse,
drcmdevmse = drcmd_evmse) %>%
mutate(onestepest=winsorize(onestepest),
pluginest=winsorize(pluginest))
# Reshape to long format on the est vars
res_long <- res %>%
pivot_longer(cols = ends_with('est'),
names_to = 'method',
values_to = 'tau_est') %>%
mutate(method=case_when(method == 'onestepest' ~ 'Approach 1 One-step',
method == 'pluginest' ~ 'Approach 1 Plug-in',
method == 'oracleest' ~ 'Oracle',
method == 'naiveest' ~ 'Naive',
method == 'onestep_adaptest' ~ 'Adaptive one-step',
method == 'plugin_adaptest' ~ 'Adaptive plug-in',
method == 'tmlest' ~ 'TML',
method == 'tmlevmest' ~ 'Approach 2 One-step (EEM)',
method == 'cvest' ~ 'TML-CV',
method == 'tmlmidest' ~ 'Approach 2 One-step',
method == 'drcmdevmest' ~ 'drcmd EVM'
))
res_ci<- res %>%
mutate(tmlcov = ((tmlest -  qnorm(0.975)*tmlse)  <= 2.5 ) & ((tmlest +  qnorm(0.975)*tmlse)  >= 2.5 ),
onestepcov = ((onestepest -  qnorm(0.975)*onestepse)  <= 2.5 ) & ((onestepest +  qnorm(0.975)*onestepse)  >= 2.5 ),
plugincov = ((pluginest -  qnorm(0.975)*pluginse)  <= 2.5 ) & ((pluginest +  qnorm(0.975)*pluginse)  >= 2.5 ),
tmlevmcov = ((tmlevmest -  qnorm(0.975)*tmlevmse)  <= 2.5 ) & ((tmlevmest +  qnorm(0.975)*tmlevmse)  >= 2.5 ),
tmlmidcov = ((tmlmidest -  qnorm(0.975)*tmlmidse)  <= 2.5 ) & ((tmlmidest +  qnorm(0.975)*tmlmidse)  >= 2.5 ),
drcmdevmcov = ((drcmdevmest -  qnorm(0.975)*drcmdevmse)  <= 2.5 ) & ((drcmdevmest +  qnorm(0.975)*drcmdevmse)  >= 2.5 ),
) %>%
pivot_longer(cols = ends_with('cov'),
names_to = 'method',
values_to = 'cov')
# First, for tmt effect estimates
### CHANGE BACK TO MEAN
grp_vec <- c('method','omega','n','rho')
res_summ <- res_long %>% group_by(across(all_of(grp_vec))) %>%
summarize(per_bias = mean(100*(tau_est-2.5)/2.5,na.rm=T),
avg_est=mean(tau_est,na.rm=T),
rmse = sqrt(mean( (tau_est-2.5)^2 , na.rm=T) ) ) %>%
mutate(rho_desc = paste('rho =',rho))
res_summ_ci <- res_ci %>% group_by(across(all_of(grp_vec))) %>%
summarize(cov = mean(cov,na.rm=T)) %>%
mutate(rho_desc = paste('rho =',rho))
ofyesplot <- res_long %>% filter(n %in% c(1000, 2500, 5000)) %>%
filter(!(method %in% c('Adaptive one-step','Adaptive plug-in'))) %>%
mutate(rho_desc = paste('P(R=1) =',rho)) %>%
mutate(n_desc = paste('n =',n)) %>%
filter(omega==0.2) %>%  ggplot(aes(x=tau_est,y=as.factor(method),
fill=as.factor(method))) +
xlim(c(-3,8)) +
geom_density_ridges(alpha = 0.5,
scale = 1,
rel_min_height = 0.02,
quantile_lines = T,
quantiles = 0.5,
panel_scaling = F) +
facet_grid(fct_reorder(n_desc,n) ~ as.factor(rho_desc),scales='free') + theme_bw() +
theme(legend.position = 'bottom',
axis.text.y = element_blank(),  # Hide y-axis labels
axis.ticks.y = element_blank(),
plot.subtitle = element_markdown(),
plot.title = element_markdown()) +
geom_vline(xintercept = 2.5, color='black',linetype='dashed') +
labs(title='**Performance of one-step estimators**',
subtitle = 'Varying (1) overall sample size (2) relative size of validation data<br>Distribution of treatment effect estimates across 2500 iterations',
y='Method',
x='ATE estimate',
fill='Method') +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) ; ofyesplot
ofyesplot <- res_long %>% filter(n %in% c(1000, 2500, 5000)) %>%
filter(!(method %in% c('Adaptive one-step','Adaptive plug-in',
'TML','TML-CV','drcmd EVM'))) %>%
mutate(rho_desc = paste('P(R=1) =',rho)) %>%
mutate(n_desc = paste('n =',n)) %>%
filter(omega==0.2) %>%  ggplot(aes(x=tau_est,y=as.factor(method),
fill=as.factor(method))) +
xlim(c(-3,8)) +
geom_density_ridges(alpha = 0.5,
scale = 1,
rel_min_height = 0.02,
quantile_lines = T,
quantiles = 0.5,
panel_scaling = F) +
facet_grid(fct_reorder(n_desc,n) ~ as.factor(rho_desc),scales='free') + theme_bw() +
theme(legend.position = 'bottom',
axis.text.y = element_blank(),  # Hide y-axis labels
axis.ticks.y = element_blank(),
plot.subtitle = element_markdown(),
plot.title = element_markdown()) +
geom_vline(xintercept = 2.5, color='black',linetype='dashed') +
labs(title='**Performance of one-step estimators**',
subtitle = 'Varying (1) overall sample size (2) relative size of validation data<br>Distribution of treatment effect estimates across 2500 iterations',
y='Method',
x='ATE estimate',
fill='Method') +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) ; ofyesplot
# Using res_summ, plot rmse as a function of rho, with facetsf for sample size
# Omit the naive method to prevent scale from being distorted
rmseplot <- res_summ %>% filter(n %in% c(1000, 2500, 5000)) %>%
filter(!(method %in% c('Adaptive one-step','Adaptive plug-in','Naive',
'TML','TML-CV'))) %>%
mutate(n_desc = paste('n =',n)) %>%
ggplot(aes(x=rho,y=rmse,group=method,color=method)) +
geom_line(size=0.7) + geom_point() +
facet_wrap(~n_desc) +
labs(title='**RMSE of treatment effect estimates**',
subtitle = 'Varying (1) overall sample size (2) relative size of validation data',
x='P(R=1)',
y='RMSE',
color='Method') +
theme_bw() +
theme(legend.position = 'bottom',
plot.subtitle = element_markdown(),
plot.title = element_markdown()) ; rmseplot
# Using res_summ, plot rmse as a function of rho, with facetsf for sample size
# Omit the naive method to prevent scale from being distorted
rmseplot <- res_summ %>% filter(n %in% c(1000, 2500, 5000)) %>%
filter(!(method %in% c('Adaptive one-step','Adaptive plug-in','Naive',
'TML','TML-CV','drcmd EVM'))) %>%
mutate(n_desc = paste('n =',n)) %>%
ggplot(aes(x=rho,y=rmse,group=method,color=method)) +
geom_line(size=0.7) + geom_point() +
facet_wrap(~n_desc) +
labs(title='**RMSE of treatment effect estimates**',
subtitle = 'Varying (1) overall sample size (2) relative size of validation data',
x='P(R=1)',
y='RMSE',
color='Method') +
theme_bw() +
theme(legend.position = 'bottom',
plot.subtitle = element_markdown(),
plot.title = element_markdown()) ; rmseplot
rmseplot <- res_summ %>% filter(n %in% c(1000)) %>%
filter((method %in% c('Approach 2 One-step (EEM)',
'Approach 2 One-step',
'drcmd EVM'))) %>%
mutate(n_desc = paste('n =',n)) %>%
ggplot(aes(x=rho,y=rmse,group=method,color=method)) +
geom_line(size=0.7) + geom_point() +
facet_wrap(~n_desc) +
labs(title='**RMSE of treatment effect estimates**',
subtitle = 'Varying (1) overall sample size (2) relative size of validation data',
x='P(R=1)',
y='RMSE',
color='Method') +
theme_bw() +
theme(legend.position = 'bottom',
plot.subtitle = element_markdown(),
plot.title = element_markdown()) ; rmseplot
rmseplot <- res_summ %>% filter(n %in% c(1000, 2500, 5000)) %>%
filter(!(method %in% c('Adaptive one-step','Adaptive plug-in',
'TML','TML-CV','Approach 2 One-step',
'drcmd EVM'))) %>%
ggplot(aes(x=rho,y=rmse,group=method,color=method)) +
geom_line(size = 0.8, linetype = "solid") +  # Slightly thicker, solid lines
geom_point(size = 2.5, shape = 21, fill = "white", stroke = 1.2) +
facet_wrap(~paste0('n=',n)) +
labs(title='**RMSE of treatment effect estimates**',
subtitle = 'Varying (1) overall sample size (2) relative size of validation data',
x='P(R=1)',
y='RMSE',
color='Method') +
theme_bw() +
theme(legend.position = 'bottom',
plot.subtitle = element_markdown(),
plot.title = element_markdown(),
panel.grid.major = element_line(size = 0.40),  # Lighter gridlines
panel.grid.minor = element_line(size=0),  # Remove minor gridlines for a cleaner look
strip.background = element_blank(),  # Remove facet background for a sleeker look
strip.text = element_text(size = 13, face = "bold"),  # Bold facet titles for emphasis
)  ; rmseplot
rmseplot <- res_summ %>% filter(n %in% c(1000, 2500, 5000)) %>%
filter(!(method %in% c('Adaptive one-step','Adaptive plug-in',
'TML','TML-CV',
'drcmd EVM'))) %>%
ggplot(aes(x=rho,y=rmse,group=method,color=method)) +
geom_line(size = 0.8, linetype = "solid") +  # Slightly thicker, solid lines
geom_point(size = 2.5, shape = 21, fill = "white", stroke = 1.2) +
facet_wrap(~paste0('n=',n)) +
labs(title='**RMSE of treatment effect estimates**',
subtitle = 'Varying (1) overall sample size (2) relative size of validation data',
x='P(R=1)',
y='RMSE',
color='Method') +
theme_bw() +
theme(legend.position = 'bottom',
plot.subtitle = element_markdown(),
plot.title = element_markdown(),
panel.grid.major = element_line(size = 0.40),  # Lighter gridlines
panel.grid.minor = element_line(size=0),  # Remove minor gridlines for a cleaner look
strip.background = element_blank(),  # Remove facet background for a sleeker look
strip.text = element_text(size = 13, face = "bold"),  # Bold facet titles for emphasis
)  ; rmseplot
View(res_summ)
head(res_summ)
ress_summ_long <- res_summ %>%
pivot_longer(cols=c('per_bias','avg_est','rmse'),
names_to = 'outcome',
values_to = 'value')
View(ress_summ_long)
res_sum_long %>%
ggplot(aes(x=rho, y=value, group=method,color=method)) +
geom_line(size = 0.8, linetype = "solid") +  # Slightly thicker, solid lines
geom_point(size = 2.5, shape = 21, fill = "white", stroke = 1.2) +
facet_grid(outcome ~ n)
res_summ_long %>%
ggplot(aes(x=rho, y=value, group=method,color=method)) +
geom_line(size = 0.8, linetype = "solid") +  # Slightly thicker, solid lines
geom_point(size = 2.5, shape = 21, fill = "white", stroke = 1.2) +
facet_grid(outcome ~ n)
res_summ_long <- res_summ %>%
pivot_longer(cols=c('per_bias','avg_est','rmse'),
names_to = 'outcome',
values_to = 'value')
res_summ_long %>%
ggplot(aes(x=rho, y=value, group=method,color=method)) +
geom_line(size = 0.8, linetype = "solid") +  # Slightly thicker, solid lines
geom_point(size = 2.5, shape = 21, fill = "white", stroke = 1.2) +
facet_grid(outcome ~ n)
res_summ_long %>%
ggplot(aes(x=rho, y=value, group=method,color=method)) +
geom_line(size = 0.8, linetype = "solid") +  # Slightly thicker, solid lines
geom_point(size = 2.5, shape = 21, fill = "white", stroke = 1.2) +
facet_grid(outcome ~ n) + theme_bw()
res_summ_long %>%
ggplot(aes(x=rho, y=value, group=method,color=method)) +
geom_line(size = 0.8, linetype = "solid") +  # Slightly thicker, solid lines
geom_point(size = 2.5, shape = 21, fill = "white", stroke = 1.2) +
facet_grid(outcome ~ n, scales = 'free') + theme_bw()
res_summ_long %>%
filter(!(method %in% c('Adaptive one-step','Adaptive plug-in',
'TML','TML-CV',
'drcmd EVM'))) %>%
ggplot(aes(x=rho, y=value, group=method,color=method)) +
geom_line(size = 0.8, linetype = "solid") +  # Slightly thicker, solid lines
geom_point(size = 2.5, shape = 21, fill = "white", stroke = 1.2) +
facet_grid(outcome ~ n, scales = 'free') + theme_bw()
res_summ_long %>%
filter(!(method %in% c('Adaptive one-step','Adaptive plug-in',
'TML','TML-CV',
'drcmd EVM'))) %>%
ggplot(aes(x=rho, y=value, group=method,color=method)) +
geom_line(size = 0.8, linetype = "solid") +  # Slightly thicker, solid lines
geom_point(size = 2.5, shape = 21, fill = "white", stroke = 1.2) +
facet_grid(outcome ~ n, scales = 'free') + theme_bw() +
theme(legend.position = 'bottom')
res_summ_long %>%
filter(!(method %in% c('Adaptive one-step','Adaptive plug-in',
'TML','TML-CV',
'drcmd EVM'))) %>%
filter(outcome != 'avg_est') %>%
ggplot(aes(x=rho, y=value, group=method,color=method)) +
geom_line(size = 0.8, linetype = "solid") +  # Slightly thicker, solid lines
geom_point(size = 2.5, shape = 21, fill = "white", stroke = 1.2) +
facet_grid(outcome ~ n, scales = 'free') + theme_bw() +
theme(legend.position = 'bottom')
res_summ_long %>%
filter(!(method %in% c('Adaptive one-step','Adaptive plug-in',
'TML','TML-CV',
'drcmd EVM'))) %>%
filter(outcome != 'avg_est') %>%
mutate(outcome = ifelse(outcome=='per_bias', 'Percent bias', 'RMSE'))
res_summ_long %>%
filter(!(method %in% c('Adaptive one-step','Adaptive plug-in',
'TML','TML-CV',
'drcmd EVM'))) %>%
filter(outcome != 'avg_est') %>%
mutate(outcome = ifelse(outcome=='per_bias', 'Percent bias', 'RMSE')) %>%
ggplot(aes(x=rho, y=value, group=method,color=method)) +
geom_line(size = 0.8, linetype = "solid") +  # Slightly thicker, solid lines
geom_point(size = 2.5, shape = 21, fill = "white", stroke = 1.2) +
facet_grid(outcome ~ n, scales = 'free') + theme_bw() +
theme(legend.position = 'bottom')
res_summ_long %>%
filter(!(method %in% c('Adaptive one-step','Adaptive plug-in',
'TML','TML-CV'))) %>%
filter(outcome != 'avg_est') %>%
mutate(outcome = ifelse(outcome=='per_bias', 'Percent bias', 'RMSE')) %>%
ggplot(aes(x=rho, y=value, group=method,color=method)) +
geom_line(size = 0.8, linetype = "solid") +  # Slightly thicker, solid lines
geom_point(size = 2.5, shape = 21, fill = "white", stroke = 1.2) +
facet_grid(outcome ~ n, scales = 'free') + theme_bw() +
theme(legend.position = 'bottom')
m_hata = ifelse(data$A==1,m_hat1,m_hat0)
